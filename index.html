<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments">
  <meta name="keywords" content="MLA-Trust">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> MLA-Trust </title>

  <!-- <link rel="icon" href="./static/images/multitrust.png"> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./data/model_scores.js" defer></script>
  <script src="./static/js/leaderboard_multitrust.js"></script> 
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<div class="header">
  <div class="container is-widescreen">
  <div class="columns is-centered">
    <div class="column has-text-centered">
      <h1>
        <!-- <img src="static/images/multitrust.png" style="width:1.8em;vertical-align: middle" alt="Logo"/> -->
        <span style="vertical-align: middle"> MLA-Trust </span>
      </h1>
      <h2 class="is-size-3">Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments</h2>
      <div class="is-size-5 publication-authors">
        <br>
        <span class="author-block">
          <a href="https://scholar.google.com/citations?user=bwkwp0MAAAAJ&hl=en">Xiao Yang*</a><sup style="color:#1db2ec">1</sup>,</span>
        <span class="author-block">
          <a href="https://scholar.google.com/citations?user=RZcc1VwAAAAJ&hl=en">Jiawei Chen*</a><sup style="color:#f31a1a">2</sup>,</span>
        <span class="author-block">
          <a href="https://mla-trust.github.io/">Jun Luo</a><sup style="color:#1db2ec">1</sup>,</span>
        <span class="author-block">
          <a href="https://scholar.google.com/citations?user=v5lIRxUAAAAJ&hl=en&oi=ao">Zhengwei Fang</a><sup style="color:#1db2ec">1</sup>,</span>
        <span class="author-block">
          <a href="https://scholar.google.com/citations?user=6_4ad84AAAAJ&hl=en&oi=ao">Yinpeng Dong</a><sup style="color:#1db2ec">1</sup>,</span>
        <span class="author-block">
          <a href="https://scholar.google.com/citations?user=dxN1_X0AAAAJ&hl=en">Hang Su</a><sup style="color:#1db2ec">1</sup>,</span>
        <span class="author-block">
          <a href="https://scholar.google.com/citations?user=axsP38wAAAAJ&hl=en">Jun Zhu</a><sup style="color:#1db2ec">1</sup>,</span>
      </div>

      <div class="is-size-5 publication-authors">
        <span class="author-block"><sup style="color:#1db2ec">1</sup>Tsinghua University,</span>
        <span class="author-block"><sup style="color:#f31a1a">2</sup>East China Normal University</span>
        <!-- <span class="author-block"><sup style="color:#f31a1a">2</sup>Beihang University,</span> -->
        <!-- <span class="author-block"><sup style="color:#ffac33">3</sup>Shanghai Jiaotong University,</span>
        <span class="author-block"><sup style="color:#ec1de2">4</sup>RealAI</span> -->
      </div>
      <div class="column has-text-centered">
        <div class="publication-links">
          <!-- PDF Link. -->
          <span class="link-block">
            <!-- @PAN TODO: change links -->
            <a href="https://arxiv.org/pdf/2506.01616"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <i class="fas fa-file-pdf"></i>
              </span>
              <span>Paper</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://arxiv.org/pdf/2506.01616"
               class="external-link button is-normal is-rounded is-dark">
            <!-- <a href="https://lupantech.github.io/papers/arxiv23_mathvista.pdf"
               class="external-link button is-normal is-rounded is-dark"> -->
              <span class="icon">
                  <i class="ai ai-arxiv"></i>
              </span>
              <span>arXiv</span>
            </a>
          </span>
          <!-- Code Link. -->
          <span class="link-block">
            <a href="https://mla-trust.github.io/"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
              </a>
          </span>
          <!-- Dataset Link. -->
          <span class="link-block">
            <a href="https://mla-trust.github.io/"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <!-- <i class="far fa-images"></i> -->
                  <p style="font-size:18px">ü§ó</p>
                  <!-- üîó -->
              </span>
              <span>Dataset</span>
            </a>
          </span>
          <!-- Leaderboard Link. -->
          <span class="link-block">
            <a href="https://mla-trust.github.io/"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <p style="font-size:18px">üèÜ</p>
              </span>
              <span>Leaderboard</span>
            </a>
          </span>
        </div>
      </div>
    </div>
  </div>
  </div>
</div>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;margin-top: 2vh">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <img src="static/images/framework.png" alt="framework" width="95%"/>
        <div class="content has-text-justified">
          <p>
            <!-- Despite the superior capabilities of <b>Multimodal Large Language Models (MLLMs)</b> across diverse tasks, they still face significant trustworthiness challenges. Yet, current literature on the assessment of trustworthy MLLMs remains limited, lacking <b>a holistic evaluation</b> to offer thorough insights into future improvements. -->
            The emergence of 
            <b>ultimodal LLM-based agents (MLAs)</b>m has transformed interaction paradigms by seamlessly integrating vision, language, action and dynamic environments, enabling unprecedented autonomous capabilities across GUI applications ranging from web automation to mobile systems. However, MLAs introduce critical trustworthiness challenges that extend far beyond traditional language models‚Äô limitations, as they can directly modify digital states and trigger irreversible real-world consequences. Existing benchmarks inadequately tackle these unique challenges posed by MLAs‚Äô actionable outputs, longhorizon uncertainty and multimodal attack vectors. In this paper, we introduce 
            <b>MLA-Trust</b>, the first comprehensive and unified framework that evaluates the MLA trustworthiness across four principled dimensions: truthfulness, controllability, safety and privacy. We utilize 
            <b>websites and mobile applications</b> as realistic testbeds, designing 34 high-risk interactive tasks and curating rich evaluation datasets. Large-scale experiments involving 13 state-of-the-art agents reveal previously unexplored trustworthiness vulnerabilities unique to multimodal interactive scenarios. For instance, proprietary and open-source GUI-interacting MLAs pose more severe trustworthiness risks than static MLLMs, particularly in high-stakes domains; the transition from static MLLMs into interactive MLAs considerably compromises trustworthiness, enabling harmful content generation in multi-step interactions that standalone MLLMs would typically prevent; multi-step execution, while enhancing the adaptability of MLAs, involves latent nonlinear risk accumulation across successive interactions, circumventing existing safeguards and resulting in unpredictable derived risks. Moreover, we present an extensible toolbox to facilitate continuous evaluation of MLA trustworthiness across diverse interactive environments. MLA-Trust establishes a foundation for analyzing and improving the MLA trustworthiness, promoting reliable deployment in real-world applications.
          </p>
          <!-- <p>
            In this work, we establish <b>MultiTrust</b>, the first comprehensive and unified benchmark on the trustworthiness of MLLMs across five primary aspects: <i>truthfulness</i>, <i>safety</i>, <i>robustness</i>, <i>fairness</i>, and <i>privacy</i>. Our benchmark employs a rigorous evaluation strategy that addresses both <b>multimodal risks</b> and <b>cross-modal impacts</b>, encompassing 32 diverse tasks with self-curated datasets.
          </p>
          <p>
            Extensive experiments with 21 modern MLLMs reveal some previously unexplored trustworthiness issues and risks, highlighting the complexities introduced by the multimodality and underscoring the necessity for advanced methodologies to enhance their reliability. For instance, typical proprietary models still struggle with the perception of visually confusing images and are vulnerable to multimodal jailbreaking and adversarial attacks; MLLMs are more inclined to disclose privacy in text and reveal ideological and cultural biases even when paired with irrelevant images in inference, indicating that the multimodality amplifies the internal risks from base LLMs.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>


<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="task">Task Pool</h2>
        <!-- <img src="static/images/task-description.png" alt="task-description" width="70%"/> -->
        <img src="static/images/task-list.png" alt="task-list" width="90%"/>
        <div class="content has-text-justified">
          <p class="mt-3">
            <!-- <b>Task Overview:</b> We organize a two-level taxonomy containing 10 sub-aspects to better categorize the target behaviors to be evaluated. Based on the taxonomy, we curate 32 diverse tasks to cover realistic and comprehensive scenarios with trustworthy risks, including generative and discriminative, multimodal and text-only ones, as summarized above. To tackle the current lack of datasets dedicated for various scenarios under these sub-aspects, we construct 20 datasets based on the existing text, image, and multimodal datasets by adapting prompts, images, and annotations with both manual efforts and automatic methods. We further propose 8 novel datasets from scratch by collecting images from the Internet or synthesizing images with Stable Diffusion and other algorithms specifically for the designed tasks.<br> 
            <img src="static/images/icon/circle-xmark-regular.svg" style="width:1.0em;vertical-align: middle" alt="circle-xmark"/> : off-the-shelf datasets from prior work; <img src="static/images/icon/circle-plus-solid.svg" style="width:1.0em;vertical-align: middle" alt="circle-plus"/> : datasets adapted to new tasks with additional images, prompts, and annotations; <img src="static/images/icon/circle-check-solid.svg" style="width:1.0em;vertical-align: middle" alt="circle-check"/> : datasets constructed from scratch. <img src="static/images/icon/file-image-regular.svg" style="width:1.0em;vertical-align: middle" alt="file-image"/> : tasks for revealing multimodal risks; <img src="static/images/icon/file-lines-regular.svg" style="width:1.0em;vertical-align: middle" alt="file-text"/> : tasks for studying cross-modal impacts. <img src="static/images/icon/circle-regular.svg" style="width:1.0em;vertical-align: middle" alt="circle"/> : rule-based evaluation (e.g., keywords matching); <img src="static/images/icon/circle-solid.svg" style="width:1.0em;vertical-align: middle" alt="circle-solid"/> : automatic evaluation by GPT-4 or other classifiers; <img src="static/images/icon/circle-half-stroke-solid.svg" style="width:1.0em;vertical-align: middle" alt="circle-left"/> : mixture evaluation. ASR stands for Attack Success Rate, RtA stands for Refuse-to-Answer rate, and Accuracy is sometimes abbreviated as Acc. -->

            <!-- Task Overview. Each task ID is linked to the section in Appendix. : website task; I: mobile task; √Æ: mixture task. ¬ñ: datasets improved design from existing datasets; ¬•: datasets constructed from scratch; √´: datasets involving user image input. $: predefined process task; ¬∂: contextual reasoning task. ‚óã: rule-based evaluation(e.g., keywords matching); ‚óã: automatic evaluation by GPT-4 or other classifiers; : mixture evaluation. RtE stands for Refuse-to-Execute rate and ASR stands for Attack Success Rate. -->
          </p>  
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered content">
        <div class="content">
          <p class="title is-3" id="leaderboard">Leaderboard in MultiTrust (Updating...)
          </p>
          <div id="multitrust_leaderboard"></div>
        </div>
      </div>
    </div>
  </div>
</section> -->


<!-- @PAN TODO: bibtex -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content" style="margin-bottom: 2vh;">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
@misc{zhang2024benchmarking,
      title={Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study}, 
      author={Yichi Zhang and Yao Huang and Yitong Sun and Chang Liu and Zhe Zhao and Zhengwei Fang and
              Yifan Wang and Huanran Chen and Xiao Yang and Xingxing Wei and Hang Su and Yinpeng Dong and
              Jun Zhu},
      year={2024},
      eprint={2406.07057},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
    }     
    </code></pre>
  </div>
</section> -->



<!-- <footer class="footer">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://mathvista.github.io/"><span class="mathvista">MathVista</span></a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
</footer> -->

</body>
</html>
